{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标量、向量、矩阵的求导\n",
    "作者：Wanying \n",
    "日期: 2025年1月\n",
    "\n",
    "## 1.分母布局与分子布局\n",
    "\n",
    "在机器学习、深度学习和优化问题中，经常会涉及到标量、向量和矩阵的求导操作。为了统一符号和计算规则，通常会采用两种布局方式来书写导数：**分母布局**和**分子布局**。\n",
    "\n",
    "### 1.1 分母布局\n",
    "\n",
    "分母布局是指将目标函数的变量（或张量）视为导数结果的分母。例如：\n",
    "\n",
    "- **标量对向量求导**: 若 $f$ 是标量，$\\mathbf{x}$ 是向量，\n",
    "  $$ \\frac{\\partial f}{\\partial \\mathbf{x}} = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} & \\frac{\\partial f}{\\partial x_2} & \\cdots & \\frac{\\partial f}{\\partial x_n} \\end{bmatrix}^T $$\n",
    "  导数结果是一个列向量。\n",
    "\n",
    "- **向量对向量求导**: 若 $\\mathbf{y}$ 是向量，$\\mathbf{x}$ 是向量，\n",
    "  $$ \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \\begin{bmatrix} \\frac{\\partial y_1}{\\partial x_1} & \\cdots & \\frac{\\partial y_1}{\\partial x_n} \\\\\n",
    "  \\vdots & \\ddots & \\vdots \\\\\n",
    "  \\frac{\\partial y_m}{\\partial x_1} & \\cdots & \\frac{\\partial y_m}{\\partial x_n} \\end{bmatrix}, $$\n",
    "  导数结果是一个矩阵。\n",
    "\n",
    "### 1.2 分子布局\n",
    "\n",
    "分子布局是指将目标函数的变量（或张量）视为导数结果的分子。例如：\n",
    "\n",
    "- **标量对向量求导**: 若 $f$ 是标量，$\\mathbf{x}$ 是向量，\n",
    "  $$ \\frac{\\partial \\mathbf{x}}{\\partial f} = \\begin{bmatrix} \\frac{\\partial x_1}{\\partial f} & \\frac{\\partial x_2}{\\partial f} & \\cdots & \\frac{\\partial x_n}{\\partial f} \\end{bmatrix}. $$\n",
    "\n",
    "- **向量对向量求导**: 若 $\\mathbf{y}$ 是向量，$\\mathbf{x}$ 是向量，\n",
    "  $$ \\frac{\\partial \\mathbf{x}}{\\partial \\mathbf{y}} = \\begin{bmatrix} \\frac{\\partial x_1}{\\partial y_1} & \\cdots & \\frac{\\partial x_1}{\\partial y_m} \\\\\n",
    "  \\vdots & \\ddots & \\vdots \\\\\n",
    "  \\frac{\\partial x_n}{\\partial y_1} & \\cdots & \\frac{\\partial x_n}{\\partial y_m} \\end{bmatrix}. $$\n",
    "\n",
    "总结来说，分母布局和分子布局的区别主要体现在导数矩阵的转置上。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 标量对向量求导\n",
    "\n",
    "假设我们有一个标量函数：\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = \\mathbf{w}^T \\mathbf{x} + b\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $\\mathbf{w} = \\begin{bmatrix} w_1 & w_2 & w_3 \\end{bmatrix}^T$ 是一个 3 维列向量；\n",
    "- $\\mathbf{x} = \\begin{bmatrix} x_1 & x_2 & x_3 \\end{bmatrix}^T$ 是一个 3 维列向量；\n",
    "- $b$ 是标量常数。\n",
    "\n",
    "我们希望求 $\\\\frac{\\\\partial f}{\\\\partial \\\\mathbf{x}}$，即向量 $\\mathbf{x}$ 的每个分量对 $f$ 的偏导数。\n",
    "\n",
    "### 2.1 第一步：展开函数\n",
    "将函数 $f(\\mathbf{x})$ 展开成具体形式：\n",
    "$$\n",
    "f(\\mathbf{x}) = w_1 x_1 + w_2 x_2 + w_3 x_3 + b\n",
    "$$\n",
    "\n",
    "### 2.2 第二步：求每个分量的偏导数\n",
    "对 $\\mathbf{x}$ 中的每个分量 $x_i$ 求偏导数：\n",
    "\n",
    "- 对 $x_1$ 求导：\n",
    "  $$\n",
    "  \\frac{\\partial f}{\\partial x_1} = w_1\n",
    "  $$\n",
    "- 对 $x_2$ 求导：\n",
    "  $$\n",
    "  \\frac{\\partial f}{\\partial x_2} = w_2\n",
    "  $$\n",
    "- 对 $x_3$ 求导：\n",
    "  $$\n",
    "  \\frac{\\partial f}{\\partial x_3} = w_3\n",
    "  $$\n",
    "\n",
    "### 2.3 第三步：将结果整理成向量形式\n",
    "将所有偏导数写成列向量：\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial \\mathbf{x}} = \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial x_1} \\\\\n",
    "\\frac{\\partial f}{\\partial x_2} \\\\\n",
    "\\frac{\\partial f}{\\partial x_3}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "w_3\n",
    "\\end{bmatrix} = \\mathbf{w}\n",
    "$$\n",
    "\n",
    "#### 结论\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial \\mathbf{x}} = \\mathbf{w}\n",
    "$$\n",
    "\n",
    "#### 代码验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T11:11:33.555539Z",
     "start_time": "2025-01-06T11:11:33.002810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x) = 25\n",
      "∂f/∂x = [2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义参数\n",
    "w = np.array([2, 3, 4])  # 权重向量 w\n",
    "x = np.array([1, 2, 3])  # 输入向量 x\n",
    "b = 5  # 常数偏置 b\n",
    "\n",
    "# 定义函数 f(x)\n",
    "f = np.dot(w, x) + b\n",
    "\n",
    "# 对 x 求偏导数，结果应该是向量 w\n",
    "df_dx = w\n",
    "\n",
    "print(\"f(x) =\", f)\n",
    "print(\"∂f/∂x =\", df_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3 向量对向量求导\n",
    "\n",
    "假设我们有一个向量函数：\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{A} \\mathbf{x}\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $\\mathbf{A}$ 是一个 $2 \\times 3$ 矩阵，\n",
    "  $$\n",
    "  \\mathbf{A} = \\begin{bmatrix}\n",
    "  a_{11} & a_{12} & a_{13} \\\\\n",
    "  a_{21} & a_{22} & a_{23}\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "- $\\mathbf{x}$ 是一个 3 维列向量，\n",
    "  $$\n",
    "  \\mathbf{x} = \\begin{bmatrix}\n",
    "  x_1 \\\\\n",
    "  x_2 \\\\\n",
    "  x_3\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "- $\\mathbf{y}$ 是一个 2 维列向量，\n",
    "  $$\n",
    "  \\mathbf{y} = \\begin{bmatrix}\n",
    "  y_1 \\\\\n",
    "  y_2\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "\n",
    "目标是求 $\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}}$。\n",
    "\n",
    "### 3.1 第一步：展开函数\n",
    "展开 $\\mathbf{y}$ 的每个分量：\n",
    "- $y_1$ 是 $\\mathbf{A}$ 的第 1 行与 $\\mathbf{x}$ 的点积：\n",
    "  $$\n",
    "  y_1 = a_{11}x_1 + a_{12}x_2 + a_{13}x_3\n",
    "  $$\n",
    "- $y_2$ 是 $\\mathbf{A}$ 的第 2 行与 $\\mathbf{x}$ 的点积：\n",
    "  $$\n",
    "  y_2 = a_{21}x_1 + a_{22}x_2 + a_{23}x_3\n",
    "  $$\n",
    "\n",
    "### 3.2 第二步：求偏导数\n",
    "对 $\\mathbf{x}$ 的每个分量 $x_j$ 求偏导数，构造雅可比矩阵 $\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}}$：\n",
    "\n",
    "- 第 1 行（对应 $y_1$）：\n",
    "  $$\n",
    "  \\frac{\\partial y_1}{\\partial x_1} = a_{11}, \\quad \\frac{\\partial y_1}{\\partial x_2} = a_{12}, \\quad \\frac{\\partial y_1}{\\partial x_3} = a_{13}\n",
    "  $$\n",
    "\n",
    "- 第 2 行（对应 $y_2$）：\n",
    "  $$\n",
    "  \\frac{\\partial y_2}{\\partial x_1} = a_{21}, \\quad \\frac{\\partial y_2}{\\partial x_2} = a_{22}, \\quad \\frac{\\partial y_2}{\\partial x_3} = a_{23}\n",
    "  $$\n",
    "\n",
    "### 3.3 第三步：构造结果\n",
    "将导数整理成矩阵形式：\n",
    "$$\n",
    "\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \\begin{bmatrix}\n",
    "\\frac{\\partial y_1}{\\partial x_1} & \\frac{\\partial y_1}{\\partial x_2} & \\frac{\\partial y_1}{\\partial x_3} \\\\\n",
    "\\frac{\\partial y_2}{\\partial x_1} & \\frac{\\partial y_2}{\\partial x_2} & \\frac{\\partial y_2}{\\partial x_3}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "a_{11} & a_{12} & a_{13} \\\\\n",
    "a_{21} & a_{22} & a_{23}\n",
    "\\end{bmatrix} = \\mathbf{A}\n",
    "$$\n",
    "\n",
    "#### 结论\n",
    "$$\n",
    "\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \\mathbf{A}\n",
    "$$\n",
    "\n",
    "#### 代码验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数\n",
    "A = np.array([[1, 2, 3], [4, 5, 6]])  # 矩阵 A (2x3)\n",
    "x = np.array([1, 2, 3])               # 向量 x (3,)\n",
    "\n",
    "# 定义函数 y = Ax\n",
    "y = np.dot(A, x)\n",
    "\n",
    "# 对 x 求偏导数，结果应该是矩阵 A\n",
    "dy_dx = A\n",
    "\n",
    "print(\"y =\", y)\n",
    "print(\"∂y/∂x =\\n\", dy_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 标量对矩阵求导\n",
    "\n",
    "假设我们有一个标量函数：\n",
    "$$\n",
    "f(\\mathbf{A}) = \\text{tr}(\\mathbf{A}^T \\mathbf{B})\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $\\mathbf{A}$ 和 $\\mathbf{B}$ 是 $2 \\times 2$ 矩阵，\n",
    "  $$\n",
    "  \\mathbf{A} = \\begin{bmatrix}\n",
    "  a_{11} & a_{12} \\\\\n",
    "  a_{21} & a_{22}\n",
    "  \\end{bmatrix}, \\quad\n",
    "  \\mathbf{B} = \\begin{bmatrix}\n",
    "  b_{11} & b_{12} \\\\\n",
    "  b_{21} & b_{22}\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "\n",
    "目标是求 $\\frac{\\partial f}{\\partial \\mathbf{A}}$。\n",
    "\n",
    "### 4.1 第一步：展开函数\n",
    "迹运算 $\\text{tr}$ 表示矩阵对角线元素的和，因此：\n",
    "$$\n",
    "f(\\mathbf{A}) = a_{11}b_{11} + a_{22}b_{22}\n",
    "$$\n",
    "\n",
    "### 4.2 第二步：求偏导数\n",
    "对 $\\mathbf{A}$ 的每个分量 $a_{ij}$ 求偏导数：\n",
    "\n",
    "- $\\frac{\\partial f}{\\partial a_{11}} = b_{11}$\n",
    "- $\\frac{\\partial f}{\\partial a_{12}} = b_{12}$\n",
    "- $\\frac{\\partial f}{\\partial a_{21}} = b_{21}$\n",
    "- $\\frac{\\partial f}{\\partial a_{22}} = b_{22}$\n",
    "\n",
    "### 4.3 第三步：构造结果\n",
    "将偏导数结果整理成矩阵形式：\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}} = \\mathbf{B}\n",
    "$$\n",
    "\n",
    "#### 结论\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}} = \\mathbf{B}\n",
    "$$\n",
    "\n",
    "#### 代码验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数\n",
    "A = np.array([[1, 2], [3, 4]])  # 矩阵 A (2x2)\n",
    "B = np.array([[5, 6], [7, 8]])  # 矩阵 B (2x2)\n",
    "\n",
    "# 定义函数 f(A) = tr(A^T B)\n",
    "f = np.trace(np.dot(A.T, B))\n",
    "\n",
    "# 对 A 求偏导数，结果应该是矩阵 B\n",
    "df_dA = B\n",
    "\n",
    "print(\"f(A) =\", f)\n",
    "print(\"∂f/∂A =\\n\", df_dA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 5 线性回归案例中的矩阵求导\n",
    "\n",
    "### 5.1 问题描述\n",
    "\n",
    "假设一个简单的线性回归模型：\n",
    "$$\n",
    "\\mathbf{y}_{\\text{pred}} = \\mathbf{X} \\mathbf{\\beta}\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $\\mathbf{X} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{bmatrix} \\in \\mathbb{R}^{3 \\times 2}$ 是设计矩阵；\n",
    "- $\\mathbf{\\beta} = \\begin{bmatrix} \\beta_1 \\\\ \\beta_2 \\end{bmatrix} \\in \\mathbb{R}^2$ 是参数向量；\n",
    "- $\\mathbf{y}_{\\text{pred}} \\in \\mathbb{R}^3$ 是模型的预测值。\n",
    "\n",
    "我们希望最小化均方误差 (MSE) 损失函数：\n",
    "$$\n",
    "L(\\mathbf{\\beta}) = \\frac{1}{2m} \\| \\mathbf{y}_{\\text{pred}} - \\mathbf{y} \\|^2\n",
    "$$\n",
    "\n",
    "其中 $\\mathbf{y} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$ 是真实标签向量。\n",
    "\n",
    "目标：求损失函数对 $\\mathbf{\\beta}$ 的梯度 $\\frac{\\partial L}{\\partial \\mathbf{\\beta}}$。\n",
    "\n",
    "\n",
    "\n",
    "### 5.2 推导过程\n",
    "\n",
    "#### 展开损失函数\n",
    "\n",
    "首先，写出 $\\mathbf{y}_{\\text{pred}}$ 的定义：\n",
    "$$\n",
    "\\mathbf{y}_{\\text{pred}} = \\mathbf{X} \\mathbf{\\beta} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{bmatrix} \\cdot \\begin{bmatrix} \\beta_1 \\\\ \\beta_2 \\end{bmatrix}\n",
    "= \\begin{bmatrix} 1\\beta_1 + 2\\beta_2 \\\\ 3\\beta_1 + 4\\beta_2 \\\\ 5\\beta_1 + 6\\beta_2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "误差向量为：\n",
    "$$\n",
    "\\mathbf{e} = \\mathbf{y}_{\\text{pred}} - \\mathbf{y} = \\begin{bmatrix} 1\\beta_1 + 2\\beta_2 \\\\ 3\\beta_1 + 4\\beta_2 \\\\ 5\\beta_1 + 6\\beta_2 \\end{bmatrix} - \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}\n",
    "= \\begin{bmatrix} (1\\beta_1 + 2\\beta_2 - 1) \\\\ (3\\beta_1 + 4\\beta_2 - 2) \\\\ (5\\beta_1 + 6\\beta_2 - 3) \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "损失函数为：\n",
    "$$\n",
    "L(\\mathbf{\\beta}) = \\frac{1}{2m} \\mathbf{e}^T \\mathbf{e}\n",
    "$$\n",
    "\n",
    "对于 $m = 3$，展开 $\\mathbf{e}^T \\mathbf{e}$：\n",
    "$$\n",
    "\\mathbf{e}^T \\mathbf{e} = \\left((1\\beta_1 + 2\\beta_2 - 1)^2 + (3\\beta_1 + 4\\beta_2 - 2)^2 + (5\\beta_1 + 6\\beta_2 - 3)^2\\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 对 $\\mathbf{\\beta}$ 求导\n",
    "\n",
    "我们需要对 $\\mathbf{\\beta}$ 求梯度：\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{\\beta}} = \\frac{1}{m} \\mathbf{X}^T \\mathbf{e}\n",
    "$$\n",
    "\n",
    "逐步计算：\n",
    "\n",
    "1. $\\mathbf{X}^T$ 是设计矩阵的转置：\n",
    "   $$\n",
    "   \\mathbf{X}^T = \\begin{bmatrix} \n",
    "   1 & 3 & 5 \\\\ \n",
    "   2 & 4 & 6 \n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "2. 误差向量 $\\mathbf{e}$ 为：\n",
    "   $$\n",
    "   \\mathbf{e} = \\begin{bmatrix} 1\\beta_1 + 2\\beta_2 - 1 \\\\ 3\\beta_1 + 4\\beta_2 - 2 \\\\ 5\\beta_1 + 6\\beta_2 - 3 \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "3. 计算 $\\mathbf{X}^T \\mathbf{e}$：\n",
    "   $$\n",
    "   \\mathbf{X}^T \\mathbf{e} = \\begin{bmatrix} \n",
    "   1 & 3 & 5 \\\\ \n",
    "   2 & 4 & 6 \n",
    "   \\end{bmatrix} \n",
    "   \\cdot \n",
    "   \\begin{bmatrix} \n",
    "   1\\beta_1 + 2\\beta_2 - 1 \\\\ \n",
    "   3\\beta_1 + 4\\beta_2 - 2 \\\\ \n",
    "   5\\beta_1 + 6\\beta_2 - 3 \n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "   逐项展开计算：\n",
    "   - 第 1 行：\n",
    "     $$\n",
    "     (1)(1\\beta_1 + 2\\beta_2 - 1) + (3)(3\\beta_1 + 4\\beta_2 - 2) + (5)(5\\beta_1 + 6\\beta_2 - 3)\n",
    "     $$\n",
    "   - 第 2 行：\n",
    "     $$\n",
    "     (2)(1\\beta_1 + 2\\beta_2 - 1) + (4)(3\\beta_1 + 4\\beta_2 - 2) + (6)(5\\beta_1 + 6\\beta_2 - 3)\n",
    "     $$\n",
    "\n",
    "4. 最终梯度：\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\mathbf{\\beta}} = \\frac{1}{3} \\mathbf{X}^T \\mathbf{e}\n",
    "   $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 代码验证\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# 定义矩阵和向量\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])  # 设计矩阵 (3x2)\n",
    "y = np.array([1, 2, 3])                 # 标签向量 (3,)\n",
    "beta = np.array([0.5, 0.5])             # 参数 (2,)\n",
    "\n",
    "# 计算预测值\n",
    "y_pred = np.dot(X, beta)\n",
    "\n",
    "# 计算误差向量\n",
    "e = y_pred - y\n",
    "\n",
    "# 样本数\n",
    "m = len(y)\n",
    "\n",
    "# 计算梯度\n",
    "grad_L = (1 / m) * np.dot(X.T, e)\n",
    "\n",
    "print(\"预测值 y_pred =\", y_pred)\n",
    "print(\"误差向量 e =\", e)\n",
    "print(\"梯度 grad_L =\", grad_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 6 矩阵求导的链式法则（展开计算）\n",
    "\n",
    "### 6.1 问题描述\n",
    "\n",
    "假设有两个函数：\n",
    "1. $\\mathbf{y} = \\mathbf{A} \\mathbf{x}$\n",
    "2. $f(\\mathbf{y}) = \\mathbf{y}^T \\mathbf{y}$\n",
    "\n",
    "其中：\n",
    "- $\\mathbf{A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\in \\mathbb{R}^{2 \\times 2}$ 是矩阵；\n",
    "- $\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\in \\mathbb{R}^2$ 是向量；\n",
    "- $\\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix} \\in \\mathbb{R}^2$ 是向量。\n",
    "\n",
    "目标：求 $f$ 关于 $\\mathbf{x}$ 的梯度 $\\frac{\\partial f}{\\partial \\mathbf{x}}$。\n",
    "\n",
    "\n",
    "\n",
    "### 6.2 推导过程\n",
    "\n",
    "#### 第一步：逐步展开函数\n",
    "1. 计算 $\\mathbf{y}$：\n",
    "   $$\n",
    "   \\mathbf{y} = \\mathbf{A} \\mathbf{x} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 1x_1 + 2x_2 \\\\ 3x_1 + 4x_2 \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "2. 计算 $f(\\mathbf{y})$：\n",
    "   $$\n",
    "   f(\\mathbf{y}) = \\mathbf{y}^T \\mathbf{y} = y_1^2 + y_2^2\n",
    "   $$\n",
    "\n",
    "#### 第二步：对 $\\mathbf{y}$ 求导\n",
    "对 $\\mathbf{y}$ 求导：\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial \\mathbf{y}} = 2 \\mathbf{y}\n",
    "$$\n",
    "\n",
    "#### 第三步：对 $\\mathbf{x}$ 求导\n",
    "由于 $\\mathbf{y} = \\mathbf{A} \\mathbf{x}$，我们有：\n",
    "$$\n",
    "\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \\mathbf{A}\n",
    "$$\n",
    "\n",
    "根据链式法则：\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial \\mathbf{x}} = \\frac{\\partial f}{\\partial \\mathbf{y}} \\cdot \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}}\n",
    "$$\n",
    "\n",
    "代入：\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial \\mathbf{x}} = (2 \\mathbf{y})^T \\mathbf{A}\n",
    "$$\n",
    "\n",
    "将 $\\mathbf{y}$ 替换回去：\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial \\mathbf{x}} = 2 (\\mathbf{A} \\mathbf{x})^T \\mathbf{A}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### 代码验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义矩阵 A 和向量 x\n",
    "A = np.array([[1, 2], [3, 4]])  # 矩阵 A (2x2)\n",
    "x = np.array([1, 1])            # 向量 x (2,)\n",
    "\n",
    "# 计算中间变量 y 和函数值 f\n",
    "y = np.dot(A, x)                # y = A * x\n",
    "f = np.dot(y, y)                # f = y^T * y\n",
    "\n",
    "# 手动计算梯度\n",
    "df_dy = 2 * y                   # ∂f/∂y\n",
    "dy_dx = A                       # ∂y/∂x\n",
    "df_dx = np.dot(df_dy, dy_dx)    # 链式法则: ∂f/∂x = ∂f/∂y * ∂y/∂x\n",
    "\n",
    "print(\"函数值 f =\", f)\n",
    "print(\"梯度 ∂f/∂x =\", df_dx)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
